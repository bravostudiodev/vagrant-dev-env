{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install -qq matplotlib pandas\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "We have attached our Jupyter server to three different repositories in our Pachyderm pipline DAG:\n",
    "\n",
    "- **trips** - This repo is populated with a daily file that records the number of bicycle trips recorded by NYC's citibike bike sharing company on that particular day (data from [here](https://www.citibikenyc.com/system-data)).\n",
    "- **sales** - This repo includes a single CSV file called `sales.csv`.  `sales.csv` is updated daily by a pipeline that processes each file in `trips` to calculate sales for the day.  Note, here we are using a fictional multiplier, $5/trip, to calculate daily \"sales\" (i.e., these are not actually the sales figures for citibike).\n",
    "- **weather** - This repo is populated daily with a JSON file representing the weather forecast for that day from [forecast.io](https://darksky.net/forecast/40.7127,-74.0059/us12/en).\n",
    "\n",
    "By attaching to these separate points in our DAG (`trips`, `weather`, and `sales`) we can bring our data together at a particular commit (i.e., a particular point in history), without explicitly planning a pipeline stage that takes these repos as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import sales data from the `sales` repo\n",
    "Let's first grab our sales data from the `sales` repo and plot data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "salesDF = pd.read_csv('/pfs/sales/sales.csv', names=['Date', 'Sales'], parse_dates=['Date'], skip_blank_lines=True)\n",
    "salesDF.dropna(thresh=1, inplace=True)\n",
    "salesDF.sort_values(by=['Date'], inplace=True)\n",
    "salesDF = salesDF.reset_index(drop=True)\n",
    "salesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "salesDF.plot(x='Date', y='Sales', figsize=(13, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On 7/30/2016 and 7/31/2016 we can see a sharp drop in sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import trip data from the `trips` repo, join with the sales data\n",
    "We can then grab the trip count data from the `trips` repo, put that into a separate dataframe, and merge the two data frames.  This way we can join our data from multiple repos interactively to try and draw some conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trip_data = {'Date': [], 'Trips': []}\n",
    "\n",
    "for fn in os.listdir('/pfs/trips/'):\n",
    "    if os.path.isfile('/pfs/trips/' + fn):              \n",
    "        data = pd.read_csv('/pfs/trips/' + fn, parse_dates=['Date'])\n",
    "        trip_data['Trips'] += data.ix[0]['Trips over the past 24-hours (midnight to 11:59pm)'],\n",
    "        trip_data['Date'] += data.ix[0]['Date'],\n",
    "\n",
    "tripsDF = pd.DataFrame(trip_data, columns=['Date', 'Trips'])\n",
    "tripsDF.dropna(thresh=1, inplace=True)\n",
    "tripsDF.sort_values(by=['Date'], inplace=True)\n",
    "tripsDF = tripsDF.reset_index(drop=True)\n",
    "tripsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataDF = salesDF.join(tripsDF.set_index('Date'), on='Date')\n",
    "dataDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import supplemental JSON weather data from the `weather` repo, and join with our other data\n",
    "Finally, we will pull in the JSON weather data from the `weather` repo and again merge that with the sales and trip data.  We suspect that the weather likely had something to do with the poor sales on the 30th and 31st of July.  In particular we expect that precipitation might have led to the poor sales, so we will extract the daily precipitation probabilities and join that with our previously created dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precip_data = {'Date': [], 'Precipitation': []}\n",
    "for fn in os.listdir('/pfs/weather/'):\n",
    "    if os.path.isfile('/pfs/weather/' + fn):\n",
    "        with open('/pfs/weather/' + fn) as data_file:    \n",
    "            data = json.load(data_file)\n",
    "        precip_data['Precipitation'] += data['daily']['data'][0]['precipProbability'],\n",
    "        precip_data['Date'] += pd.to_datetime(fn),\n",
    "precipDF = pd.DataFrame(precip_data)\n",
    "precipDF.dropna(thresh=1, inplace=True)\n",
    "precipDF.sort_values(by=['Date'], inplace=True)\n",
    "precipDF = precipDF.reset_index(drop=True)\n",
    "precipDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataDF = dataDF.join(precipDF.set_index('Date'), on='Date')\n",
    "dataDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the sales in the context of weather\n",
    "Finally, we confirm our suspicions by visualizing the precipitation probabilities with the sales data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "ax = dataDF.plot(x='Date', secondary_y=['Precipitation'], figsize=(13, 8))\n",
    "ax.set_ylabel('Sales (dollars), # Trips')\n",
    "ax.right_ax.set_ylabel('Precipitation probability')\n",
    "ax.right_ax.legend(loc='best')\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there was a probability of precipitation in NYC above 70% both of the days in question.  This is likely to be the explanation for the poor sales.  Of course, we can attach our Jupyter notebook to any Pachyderm repos at at commit to explore other unexpected behavior, develop further analyses, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
